from .utils_model import *
from PIL import ImageOps
import torchvision


def make_dataset(
		dataset: str,
		device: torch.device = 'cpu',
		load_dir: str = 'Datasets',
		**kwargs, ):

	tst = None
	load_dir = add_home(load_dir)

	if dataset.split('-')[0] in ['vH', 'Kyoto']:
		# these are full dataset (no crop)

		# get file_name (e.g., 'vH', _, 'wht')
		ds, _, mode = dataset.partition('-')
		file_name = '_'.join(filter(None, [
			ds.lower(), mode.lower()]))
		file_name = f"{file_name}.npy"

		# get load path, load data
		path = 'DOVES' if 'vH' in dataset else 'Kyoto/processed'
		data_file = pjoin(load_dir, path, file_name)
		try:  # for np array
			data = np.load(data_file)
		except ValueError:  # for dict
			data = np.load(
				data_file,
				allow_pickle=True,
			).item()

		# split trn/vld
		if 'vH' in dataset:
			trn = data[:80]
			vld = data[80:]
		else:
			trn = data['(500,640)']
			vld = data['(640,500)']

		# map to tensor
		trn, vld = map(_to_device_fun(device), [trn, vld])

	elif any(s in dataset for s in ['vH', 'Kyoto']):
		# these are patches: vh16, vH32, Kyoto16, Kyoto32
		defaults = dict(
			shift_rescale=False,
			vld_portion=0.2,
			n_blocks=100,
		)
		kwargs = setup_kwargs(defaults, kwargs)

		match dataset.split('-')[1]:
			case 'col': file_name = 'patches_color.npy'
			case 'wht': file_name = 'processed.npy'
			case 'bw': file_name = 'patches.npy'
			case _: file_name = 'patches.npy'

		data = pjoin(
			load_dir,
			'DOVES' if 'vH' in dataset else 'Kyoto',
			dataset.split('-')[0],
			file_name,
		)
		data = np.load(data)

		if kwargs['shift_rescale']:
			mu = np.nanmean(data)
			sd = np.nanstd(data)
			data = (data - mu) / sd

		trn_inds, vld_inds = split_data(
			n_samples=len(data),
			n_blocks=kwargs['n_blocks'],
			vld_portion=kwargs['vld_portion'],
		)
		trn, vld = data[trn_inds], data[vld_inds]
		trn, vld = map(_to_device_fun(device), [trn, vld])

	elif dataset == 'CIFAR16':
		path = pjoin(load_dir, 'CIFAR10', 'xtract16')
		trn = np.load(pjoin(path, 'trn', 'processed.npy'))
		vld = np.load(pjoin(path, 'vld', 'processed.npy'))
		trn, vld = map(_to_device_fun(device), [trn, vld])

	elif dataset in ['MNIST', 'FashionMNIST']:
		path = pjoin(load_dir, dataset, 'processed')
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			# get transforms
			transform = torchvision.transforms.Compose([
				torchvision.transforms.ToTensor(),
				ToDevice(device=device),
			])
			# make dataset
			kws = dict(root=load_dir, transform=transform)
			dataset = getattr(torchvision.datasets, dataset)
			trn = dataset(train=True, **kws)
			vld = dataset(train=False, **kws)
			# process and save
			trn, vld, _ = _process_and_save(
				trn=trn, vld=vld, save_dir=path)

	elif dataset == 'EMNIST':
		path = pjoin(load_dir, 'EMNIST', 'processed')
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			# get transforms
			transform = torchvision.transforms.Compose([
				torchvision.transforms.ToTensor(),
				ToDevice(device=device),
			])
			# make dataset
			kws = dict(root=load_dir, transform=transform, split='letters')
			trn = torchvision.datasets.EMNIST(train=True, **kws)
			vld = torchvision.datasets.EMNIST(train=False, **kws)
			# process and save
			trn, vld, _ = _process_and_save(
				trn=trn,
				vld=vld,
				save_dir=path,
				transpose=True,
			)

	elif dataset == 'Omniglot':
		path = pjoin(load_dir, 'omniglot-py', 'processed')
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			# get transforms
			kws_resize = dict(
				size=28,
				antialias=True,
				interpolation=F_vis.InterpolationMode.NEAREST,
			)
			transform = torchvision.transforms.Compose([
				torchvision.transforms.Resize(**kws_resize),
				InvertBinaryPILImage(),
				torchvision.transforms.ToTensor(),
				ToDevice(device=device),
			])
			# make dataset
			kws = dict(root=load_dir, transform=transform)
			trn = torchvision.datasets.Omniglot(background=True, **kws)
			vld = torchvision.datasets.Omniglot(background=False, **kws)
			# process and save
			trn, vld, _ = _process_and_save(
				trn=trn, vld=vld, save_dir=path)

	elif dataset == 'SVHN':
		defaults = dict(grey=True)
		kwargs = setup_kwargs(defaults, kwargs)
		path = 'processed' + ('_grey' if kwargs['grey'] else '')
		path = pjoin(load_dir, 'SVHN', path)
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			# get transforms
			transform = [
				torchvision.transforms.ToTensor(),
				torchvision.transforms.Grayscale()
				if kwargs['grey'] else None,
				torchvision.transforms.Normalize(
					mean=(0.5,) * 3, std=(0.5,) * 3)
				if not kwargs['grey'] else None,
				ToDevice(device=device),
			]
			transform = torchvision.transforms.Compose([
				t for t in transform if t is not None
			])
			# make dataset
			kws = dict(
				root=pjoin(load_dir, 'SVHN'),
				transform=transform,
			)
			trn = torchvision.datasets.SVHN(split='train', **kws)
			vld = torchvision.datasets.SVHN(split='test', **kws)
			# process and save
			trn, vld, _ = _process_and_save(
				trn=trn, vld=vld, save_dir=path)

	elif dataset == 'CIFAR10':
		defaults = dict(grey=False, augment=True)
		kwargs = setup_kwargs(defaults, kwargs)
		path = 'processed' + ('_grey' if kwargs['grey'] else '')
		path = pjoin(load_dir, 'CIFAR10', path)
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			# get transforms
			transform_list = [
				torchvision.transforms.ToTensor(),
				torchvision.transforms.Grayscale()
				if kwargs['grey'] else None,
				torchvision.transforms.Normalize(
					mean=(0.5,) if kwargs['grey'] else (0.5,) * 3,
					std=(0.5,) if kwargs['grey'] else (0.5,) * 3),
				ToDevice(device=device),
			]
			transform_list = [
				t for t in transform_list
				if t is not None
			]
			transform = torchvision.transforms.Compose(
				transform_list)
			# make dataset
			kws = dict(
				root=pjoin(load_dir, 'CIFAR10'),
				transform=transform,
			)
			trn = torchvision.datasets.CIFAR10(train=True, **kws)
			vld = torchvision.datasets.CIFAR10(train=False, **kws)
			if kwargs['augment']:
				flip = torchvision.transforms.RandomHorizontalFlip(p=1.0)
				transform = torchvision.transforms.Compose(
					[flip] + transform_list)
				kws['transform'] = transform
				trn_aug = torchvision.datasets.CIFAR10(train=True, **kws)
			else:
				trn_aug = None
			# process and save
			trn, vld, _ = _process_and_save(
				trn=trn,
				vld=vld,
				trn_aug=trn_aug,
				save_dir=path,
			)

	elif dataset == 'ImageNet32':
		defaults = dict(skip_trn=False)
		kwargs = setup_kwargs(defaults, kwargs)
		path = pjoin(load_dir, dataset, 'processed')
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device, kwargs['skip_trn'])
		else:
			raise RuntimeError(dataset)

	elif dataset == 'CelebA':
		defaults = dict(mode='178')
		kwargs = setup_kwargs(defaults, kwargs)
		path = 'processed'
		if kwargs['mode']:
			path = f"{path}_{kwargs['mode']}"
		path = pjoin(load_dir, dataset, path)
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			# get transforms
			transform_list = [
				torchvision.transforms.ToTensor(),
				torchvision.transforms.Grayscale()
				if kwargs['grey'] else None,
				torchvision.transforms.Normalize(
					mean=(0.5,) if kwargs['grey'] else (0.5,) * 3,
					std=(0.5,) if kwargs['grey'] else (0.5,) * 3),
				ToDevice(device=device),
			]
			transform_list = [
				t for t in transform_list
				if t is not None
			]
			transform = torchvision.transforms.Compose(
				transform_list)
			# make dataset
			kws = dict(
				root=pjoin(load_dir, dataset),
				transform=transform,
			)
			trn = torchvision.datasets.CelebA(split='train', **kws)
			vld = torchvision.datasets.CelebA(split='valid', **kws)
			tst = torchvision.datasets.CelebA(split='test', **kws)
			# process and save
			trn, vld, tst = _process_and_save(
				trn=trn,
				vld=vld,
				tst=tst,
				save_dir=path,
			)

	elif dataset.startswith('BALLS'):
		defaults = dict(vld_split=0.25)
		kwargs = setup_kwargs(defaults, kwargs)

		# create load path
		path = pjoin(
			load_dir,
			'BALLS',
			f"npix-{int_from_str(dataset)}",
		)
		# load
		x_tst = np.load(pjoin(path, 'x_tst.npy'))
		z_tst = np.load(pjoin(path, 'z_tst.npy'))
		x = np.load(pjoin(path, 'x.npy'))
		z = np.load(pjoin(path, 'z.npy'))
		# split into trn / vld
		frac = 1 - kwargs['vld_split']
		idx = int(len(x) * frac)
		x_trn, x_vld = x[:idx], x[idx:]
		z_trn, z_vld = z[:idx], z[idx:]

		# to tensor
		x_trn, x_vld, x_tst, z_trn, z_vld, z_tst = map(
			_to_device_fun(device),
			[x_trn, x_vld, x_tst, z_trn, z_vld, z_tst],
		)
		# to dataset tuples
		trn = (x_trn, z_trn)
		vld = (x_vld, z_vld)
		tst = (x_tst, z_tst)

	elif dataset == 'DAVIS':
		defaults = dict(
			seq_len=48,
			crop_size=32,
		)
		kwargs = setup_kwargs(defaults, kwargs)
		dir_name_pattern = '-'.join([
			f"t{kwargs['seq_len']}",
			f"s{kwargs['crop_size']}",
		])
		root = pjoin(load_dir, dataset)
		item = next(
			f for f in os.listdir(root)
			if dir_name_pattern in f
		)
		path = pjoin(root, item)
		if os.path.isfile(pjoin(path, 'x_trn.npy')):
			trn, vld, tst = _load(path, device)
		else:
			raise RuntimeError(dataset)

	else:
		raise ValueError(dataset)

	trn, vld, tst = [  # ensure tuple
		x if isinstance(x, tuple) else (x,)
		for x in [trn, vld, tst]
	]
	return trn, vld, tst


def make_dataloader(
		dataset: str,
		device: torch.device,
		load_dir: str = 'Datasets',
		batch_size: int = 256,
		**kwargs, ):
	# datasets
	trn, vld, _ = make_dataset(
		dataset=dataset,
		device=device,
		load_dir=load_dir,
		**kwargs,
	)
	trn = torch.utils.data.TensorDataset(*trn)
	vld = torch.utils.data.TensorDataset(*vld)
	# dataloaders
	defaults = dict(
		batch_size=batch_size,
		drop_last=False,
		shuffle=False,
	)
	kwargs = filter_kwargs(
		fn=torch.utils.data.DataLoader,
		kw=setup_kwargs(defaults, kwargs),
	)
	dl_trn = torch.utils.data.DataLoader(trn, **kwargs)
	dl_vld = torch.utils.data.DataLoader(vld, **kwargs)
	return dl_trn, dl_vld


def split_data(
		n_samples: int,
		n_blocks: int = 1,
		vld_portion: float = 0.2, ):
	assert 0 < vld_portion < 1
	indices = range(n_samples)
	block_size = len(indices) // n_blocks

	trn_inds, vld_inds = [], []
	for b in range(n_blocks):
		start = b * block_size
		if b == n_blocks - 1:
			end = len(indices)
		else:
			end = start + block_size

		block_inds = indices[start:end]
		vld_size = np.round(len(block_inds) * vld_portion)
		trn_size = len(block_inds) - int(vld_size)

		trn_inds.extend(block_inds[:trn_size])
		vld_inds.extend(block_inds[trn_size:])

	assert not set(trn_inds).intersection(
		vld_inds), "must be non-overlapping"
	trn_inds, vld_inds = map(
		lambda x: np.array(x),
		[trn_inds, vld_inds],
	)
	return trn_inds, vld_inds


def dataset_dims(dataset: str):
	channel_sz = 1
	dim_is_in_name = (
		any(d in dataset for d in [
			'vH16', 'vH32', 'CIFAR16',
			'Kyoto16', 'Kyoto32']) or
		dataset.startswith('BALLS')
	)
	if dim_is_in_name:
		pixel_sz = int_from_str(dataset)
	elif dataset.startswith(('vH', 'Kyoto')):
		pixel_sz = -1  # will be set by crop size later
	elif dataset.startswith(('MNIST', 'EMNIST', 'Omniglot')):
		pixel_sz = 28
	elif dataset == 'SVHN':
		pixel_sz = 32
	elif dataset in ['CIFAR10', 'ImageNet32']:
		pixel_sz = 32
		channel_sz = 3
	elif dataset == 'CelebA':
		# pixel_sz = (218, 178)  # TODO: cropped
		pixel_sz = (178, 178)
		channel_sz = 3
	elif dataset == 'DAVIS':  # TODO: cropped
		pixel_sz = (32, 32)
		channel_sz = 1
	else:
		raise ValueError(dataset)
	if '-col' in dataset:
		channel_sz = 3
	if isinstance(pixel_sz, int):  # square
		pixel_sz = (pixel_sz, pixel_sz)
	dims = (channel_sz, *pixel_sz)
	return dims


class ToDevice:
	def __init__(self, device):
		self.device = device

	def __call__(self, x):
		return x.to(self.device)


class InvertBinaryPILImage(object):
	def __call__(self, img):
		# mode 'L': grayscale
		img = img.convert('L')
		return ImageOps.invert(img)


def _load(load_dir, device, skip_trn=False):
	# load numpy
	x_vld = np.load(pjoin(load_dir, 'x_vld.npy'))
	try:
		y_vld = np.load(pjoin(load_dir, 'y_vld.npy'))
	except FileNotFoundError:
		y_vld = None
	if skip_trn:
		x_trn = None
		y_trn = None
	else:
		x_trn = np.load(pjoin(load_dir, 'x_trn.npy'))
		try:
			y_trn = np.load(pjoin(load_dir, 'y_trn.npy'))
		except FileNotFoundError:
			y_trn = None
	if os.path.isfile(pjoin(load_dir, 'x_tst.npy')):
		x_tst = np.load(pjoin(load_dir, 'x_tst.npy'))
		try:
			y_tst = np.load(pjoin(load_dir, 'y_tst.npy'))
		except FileNotFoundError:
			y_tst = None
	else:
		x_tst, y_tst = None, None

	# to tensor
	x_trn, x_vld, y_trn, y_vld = map(
		_to_device_fun(device),
		[x_trn, x_vld, y_trn, y_vld],
	)
	if x_tst is not None:
		x_tst, y_tst = map(
			_to_device_fun(device),
			[x_tst, y_tst],
		)

	# to dataset tuple
	vld = (x_vld, y_vld)
	if skip_trn:
		trn = None
	else:
		trn = (x_trn, y_trn)
	if x_tst is not None:
		tst = (x_tst, y_tst)
	else:
		tst = None
	return trn, vld, tst


def _process_and_save(
		trn: torch.utils.data.Dataset | Tuple[torch.Tensor, ...],
		vld: torch.utils.data.Dataset | Tuple[torch.Tensor, ...],
		save_dir: str,
		tst: torch.utils.data.Dataset | Tuple[torch.Tensor, ...] = None,
		trn_aug: torch.utils.data.Dataset | Tuple[torch.Tensor, ...] = None,
		transpose: bool = False, ):
	# process
	x_vld, y_vld = _process(vld)
	x_trn, y_trn = _process(trn)
	if tst is not None:
		x_tst, y_tst = _process(tst)
	else:
		x_tst, y_tst = None, None
	if trn_aug is not None:
		x_trn_aug, y_trn_aug = _process(trn_aug)
	else:
		x_trn_aug, y_trn_aug = None, None
	# transpose?
	if transpose:
		x_vld = torch.swapaxes(x_vld, 2, 3)
		x_trn = torch.swapaxes(x_trn, 2, 3)
		if tst is not None:
			x_tst = torch.swapaxes(x_tst, 2, 3)
		if trn_aug is not None:
			x_trn_aug = torch.swapaxes(x_trn_aug, 2, 3)
	# concat augmented data
	if trn_aug:
		x_trn = torch.cat([x_trn, x_trn_aug])
		y_trn = torch.cat([y_trn, y_trn_aug])
	# save
	os.makedirs(save_dir, exist_ok=True)
	_save = {
		'x_trn': tonp(x_trn),
		'y_trn': tonp(y_trn),
		'x_vld': tonp(x_vld),
		'y_vld': tonp(y_vld),
	}
	if x_tst is not None:
		_save = {
			**_save,
			'x_tst': tonp(x_tst),
			'y_tst': tonp(y_tst),
		}
	for name, obj in _save.items():
		save_obj(
			obj=obj,
			file_name=name,
			save_dir=save_dir,
			verbose=True,
			mode='npy',
		)
	# to dataset tuples
	trn = (x_trn, y_trn)
	vld = (x_vld, y_vld)
	if x_tst is not None:
		tst = (x_tst, y_tst)
	return trn, vld, tst


def _process(dataset: Tuple[torch.Tensor, ...]):
	# get dataset
	if isinstance(dataset, (tuple, list)):
		dataset = torch.utils.data.TensorDataset(*dataset)
	elif isinstance(dataset, torch.utils.data.Dataset):
		pass
	else:
		raise RuntimeError(type(dataset))
	# get dataloader
	loader = torch.utils.data.DataLoader(
		dataset, batch_size=len(dataset))
	# process
	return next(iter(loader))


def _to_device_fun(
		device: torch.device,
		dtype=torch.float, ):
	def _fun(a):
		if a is None:
			return None
		return torch.tensor(
			data=a,
			dtype=dtype,
			device=device,
		)
	return _fun
